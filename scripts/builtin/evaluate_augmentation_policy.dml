#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

# Evaluate Augmentation Policy
# TODO: short description
#
# INPUT PARAMETERS:
# ----------------------------------------------------------------------------------------------------------------------
# NAME       TYPE    DEFAULT MEANING
# ----------------------------------------------------------------------------------------------------------------------
# policy     Matrix  ---     Augmentation policy to evaluate
#                            Each row represents an augmentation subpolicy
#                            For each image from the dataset an augmentation subpolicy is chosen uniformly at random
#                            A subpolicy consists of an arbitrary number of linearized transformation descriptions
#                            A transformation description consists of 3 values:
#                            * An integer defining the transformation
#                            * A double [0, 1] defining the probability of applying the transformation
#                            * A double [0, 1] defining the magnitude of the transformation
# X_train    Matrix  ---     The training dataset consisting of linearized images.
#                            Images are linearized in row-major format and one channel after the other.
# y_train    Vector  ---     The targets of the training set as a column vector
# X_test     Matrix  ---     The test dataset consisting of row-major linearized images.
# y_test     Vector  ---     The targets of the test set as a column vector
# width      Integer ---     The width of the images
# height     Integer ---     The height of the images
# channels   Integer   1     The number of channels of the images
# seed       Double   -1     The seed to use for random number generation

# RETURN VALUES
# ----------------------------------------------------------------------------------------------------------------------
# score      Double  ---     TODO: description
# ----------------------------------------------------------------------------------------------------------------------

m_evaluate_augmentation_policy = function(Matrix[Double] policy, Matrix[Double] X_train, Matrix[Double] y_train,
  Matrix[Double] X_test, Matrix[Double] y_test, Integer width, Integer height, Integer channels=1, Double seed=-1)
  return (Double score) {

  s_transform = 3
  n_samples = nrow(X_train)
  n_subpolicies = nrow(policy)
  n_transforms = ncol(policy) / s_transform

  random = rand(rows=n_samples, cols=n_transforms+1, min=0, max=1, sparsity=1, pdf="uniform", seed=seed)

  # apply augmentation policy to the training set
  X_augmented = matrix(0, rows=n_samples, cols=ncol(X_train))
  for (i in 1:n_samples) {
    img = matrix(X_train[i], rows=height, cols=width)
    subpolicy_idx = as.scalar(floor(random[i, 1] * n_subpolicies)) + 1
    for (j in 1:n_transforms) {
      transform_idx = (j-1)*s_transform
      op = as.scalar(policy[subpolicy_idx, transform_idx + 1])
      prob = as.scalar(policy[subpolicy_idx, transform_idx + 2])
      mag = as.scalar(policy[subpolicy_idx, transform_idx + 3])

      if (as.scalar(random[i, j+1]) < prob) {
        if (op == 1) {         # ShearX
          mag = mag * 0.6 - 0.3
          img = img_shear(img, mag, 0, 127)
        } else if (op == 2) {  # ShearY
          mag = mag * 0.6 - 0.3
          img = img_shear(img, 0, mag, 127)
        } else if (op == 3) {  # TranslateX
          mag = mag * 300 - 150
          img = img_translate(img, mag, 0, width, height, 127)
        } else if (op == 4) {  # TranslateY
          mag = mag * 300 - 150
          img = img_translate(img, 0, mag, width, height, 127)
        } else if (op == 5) {  # Rotate
          mag = (mag * 60 - 30) / 180 * 3.14159265
          img = img_rotate(img, mag, 127)
        } else if (op == 6) {  # AutoContrast
          # TODO
        } else if (op == 7) {  # Invert
          # TODO
        } else if (op == 8) {  # Equalize
          # TODO
        } else if (op == 9) {  # Solarize
          # TODO
        } else if (op == 10) { # Posterize
          mag = mag * 4 + 4
          img = img_posterize(img, mag)
        } else if (op == 11) { # Contrast
          # TODO
        } else if (op == 12) { # Color
          # TODO
        } else if (op == 13) { # Brightness
          # TODO
        } else if (op == 14) { # Sharpness
          # TODO
        } else if (op == 15) { # Cutout
          mag = mag * 60
          x = as.scalar(rand(rows=1, cols=1, min=0, max=max(0, width - mag), sparsity=1, pdf="uniform", seed=seed))
          y = as.scalar(rand(rows=1, cols=1, min=0, max=max(0, height - mag), sparsity=1, pdf="uniform", seed=seed))
          img = img_cutout(img, x, y, mag, mag, 127)
        } else if (op == 16) { # Sample Pairing
          mag = mag * 0.4
          img2_idx = as.scalar(rand(rows=1, cols=1, min=0, max=n_samples, sparsity=1, pdf="uniform", seed=seed))
          img2 = matrix(X_train[img2_idx], rows=height, cols=width)
          img = img_sample_pairing(img, img2, mag)
        }
      }

      X_augmented[i] = matrix(img, rows=1, cols=ncol(X_train))
    }
  }

  # TODO: create a submodel and train it using the augmented X_train
  # TODO: evaluate the submodel on the testset
  score = 0
}
